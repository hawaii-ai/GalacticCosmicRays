{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ve8yVrLbiOXv"
   },
   "outputs": [],
   "source": [
    "# Training NN with Elegy then do HMC with Oryx on Mana\n",
    "# Author: Peter Oct 24 2021\n",
    "# Requirements: \n",
    "#!module load system/CUDA/11.0.2 \n",
    "#!pip install --upgrade jax jaxlib==0.1.68+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html \n",
    "#!pip install tensorflow-io oryx elegy\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set(style='whitegrid')\n",
    "\n",
    "import os\n",
    "#os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "#os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.10'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import vmap\n",
    "from jax import jit\n",
    "from jax import grad\n",
    "assert jax.default_backend() == 'gpu'\n",
    "\n",
    "import elegy # pip install elegy\n",
    "import optax\n",
    "#import flax.linen\n",
    "import tensorflow_io as tfio # pip install tensorflow-io\n",
    "import tensorflow as tf # Recommended not to import this with jax because will also try to grab memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F51vk2W66pyG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 01:10:52.542859: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Augment to help smooth out function.\n",
    "# def add_gaussian_noise(x, y):\n",
    "#     # x must be scaled in [0, 1]\n",
    "#     with tf.name_scope('Add_gaussian_noise'):\n",
    "#         noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=.1, dtype=tf.float32)\n",
    "#         noise_x = x + noise\n",
    "#         noise_x = tf.clip_by_value(noise_x, 0.0, 1.0)\n",
    "#     return noise_x, y\n",
    "# train = train.map(add_gaussian_noise)\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #initializer = elegy.initializers.RandomNormal(stddev=.001)\n",
    "        initializer = None #elegy.initializers.TruncatedNormal()\n",
    "        x = elegy.nn.Linear(256, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        #x = elegy.nn.Dropout(0.5)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(256, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        #x = elegy.nn.Dropout(0.3)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(245, w_init=initializer, b_init=initializer)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=[elegy.losses.MeanSquaredError(),\n",
    "          #elegy.losses.MeanAbsoluteError(),\n",
    "          #elegy.regularizers.GlobalL2(l=1e-4),\n",
    "         ],\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optax.sgd(1e-10),\n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "path = 'model_2_256_selu'\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_mean_squared_error_loss\", patience=5),\n",
    "             elegy.callbacks.ModelCheckpoint(path=path, save_best_only=True, monitor='val_mean_squared_error_loss'),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10000, #10000, # 10k*128 is approximate size of training set.\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "#model.save('model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 2. try to be smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 - 32s - l2_regularization_loss: 5.6000e-04 - loss: 0.0092 - mean_squared_error_loss: 0.0086 - val_l2_regularization_loss: 4.0906e-04 - val_loss: 4.3450e-04 - val_mean_squared_error_loss: 2.5448e-05\n",
      "Epoch 2/50\n",
      "10000/10000 - 16s - l2_regularization_loss: 2.8204e-04 - loss: 2.9406e-04 - mean_squared_error_loss: 1.2021e-05 - val_l2_regularization_loss: 1.7975e-04 - val_loss: 1.8655e-04 - val_mean_squared_error_loss: 6.7999e-06\n",
      "Epoch 3/50\n",
      "10000/10000 - 16s - l2_regularization_loss: 1.2187e-04 - loss: 1.2735e-04 - mean_squared_error_loss: 5.4803e-06 - val_l2_regularization_loss: 7.8663e-05 - val_loss: 8.3152e-05 - val_mean_squared_error_loss: 4.4884e-06\n",
      "Epoch 4/50\n",
      "10000/10000 - 16s - l2_regularization_loss: 5.5707e-05 - loss: 6.0090e-05 - mean_squared_error_loss: 4.3834e-06 - val_l2_regularization_loss: 3.9462e-05 - val_loss: 4.4400e-05 - val_mean_squared_error_loss: 4.9376e-06\n",
      "Epoch 5/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 3.1409e-05 - loss: 3.5476e-05 - mean_squared_error_loss: 4.0671e-06 - val_l2_regularization_loss: 2.5494e-05 - val_loss: 2.9294e-05 - val_mean_squared_error_loss: 3.7992e-06\n",
      "Epoch 6/50\n",
      "10000/10000 - 16s - l2_regularization_loss: 2.2069e-05 - loss: 2.6058e-05 - mean_squared_error_loss: 3.9886e-06 - val_l2_regularization_loss: 1.9419e-05 - val_loss: 2.3181e-05 - val_mean_squared_error_loss: 3.7614e-06\n",
      "Epoch 7/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 1.7753e-05 - loss: 2.1757e-05 - mean_squared_error_loss: 4.0039e-06 - val_l2_regularization_loss: 1.6461e-05 - val_loss: 2.0240e-05 - val_mean_squared_error_loss: 3.7791e-06\n",
      "Epoch 8/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 1.5605e-05 - loss: 1.9661e-05 - mean_squared_error_loss: 4.0569e-06 - val_l2_regularization_loss: 1.4948e-05 - val_loss: 1.8833e-05 - val_mean_squared_error_loss: 3.8856e-06\n",
      "Epoch 9/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 1.4485e-05 - loss: 1.8593e-05 - mean_squared_error_loss: 4.1075e-06 - val_l2_regularization_loss: 1.4138e-05 - val_loss: 1.8048e-05 - val_mean_squared_error_loss: 3.9097e-06\n",
      "Epoch 10/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 1.3875e-05 - loss: 1.8027e-05 - mean_squared_error_loss: 4.1521e-06 - val_l2_regularization_loss: 1.3651e-05 - val_loss: 1.7544e-05 - val_mean_squared_error_loss: 3.8935e-06\n",
      "Epoch 11/50\n",
      "10000/10000 - 14s - l2_regularization_loss: 1.3519e-05 - loss: 1.7691e-05 - mean_squared_error_loss: 4.1720e-06 - val_l2_regularization_loss: 1.3391e-05 - val_loss: 1.7473e-05 - val_mean_squared_error_loss: 4.0816e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Augment to help smooth out function.\n",
    "# def add_gaussian_noise(x, y):\n",
    "#     # x must be scaled in [0, 1]\n",
    "#     with tf.name_scope('Add_gaussian_noise'):\n",
    "#         noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=.1, dtype=tf.float32)\n",
    "#         noise_x = x + noise\n",
    "#         noise_x = tf.clip_by_value(noise_x, 0.0, 1.0)\n",
    "#     return noise_x, y\n",
    "# train = train.map(add_gaussian_noise)\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #initializer = elegy.initializers.RandomNormal(stddev=.001)\n",
    "        initializer = None #elegy.initializers.TruncatedNormal()\n",
    "        x = elegy.nn.Linear(256, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        #x = elegy.nn.Dropout(0.5)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(256, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        #x = elegy.nn.Dropout(0.3)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(245, w_init=initializer, b_init=initializer)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=[elegy.losses.MeanSquaredError(),\n",
    "          #elegy.losses.MeanAbsoluteError(),\n",
    "          elegy.regularizers.GlobalL2(l=1e-6),\n",
    "         ],\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optax.sgd(1e-10),\n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "path = 'model_2_256_selu_l21e-6'\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_mean_squared_error_loss\", patience=5),\n",
    "             elegy.callbacks.ModelCheckpoint(path=path, save_best_only=True, monitor='val_mean_squared_error_loss'),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10000, #10000, # 10k*128 is approximate size of training set.\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "#model.save('model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 13:08:11.430107: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2021-11-18 13:08:12.336124: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 3.28 s, total: 17.5 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Make predictions on test set for analysis. \n",
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(10000))\n",
    "test = full.skip(np.floor(1435308 *.9)).take(np.floor(10000))\n",
    "# Batch\n",
    "BATCH_SIZE = 1000\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# Load Model\n",
    "model_path = 'model_2_256_selu_l21e-6'\n",
    "model = elegy.load(model_path)\n",
    "model.run_eagerly = True # Settable attribute. Required to be true for ppmodel.\n",
    "\n",
    "# Train set\n",
    "xs, ys, yhats = [], [], []\n",
    "for i,(xbatch, ybatch) in enumerate(train.as_numpy_iterator()):\n",
    "    #x, y =  x.numpy(), y.numpy()\n",
    "    yhat = model.predict(xbatch)\n",
    "    yhats.append(yhat)\n",
    "    xs.append(xbatch)\n",
    "    ys.append(ybatch)\n",
    "xs = np.concatenate(xs, axis=0)\n",
    "ys = np.concatenate(ys, axis=0)\n",
    "yhats = np.concatenate(yhats)\n",
    "assert ys.shape == yhats.shape\n",
    "assert xs.shape[0] == yhats.shape[0]\n",
    "np.savetxt(fname=f'train_inputs_10k.csv', X=xs, fmt='%.8e')\n",
    "np.savetxt(fname=f'train_targets_10k.csv', X=ys, fmt='%.8e')\n",
    "np.savetxt(fname=f'train_predictions_10k.csv', X=yhats, fmt='%.8e')\n",
    "\n",
    "# Test set\n",
    "xs, ys, yhats = [], [], []\n",
    "for i,(xbatch, ybatch) in enumerate(test.as_numpy_iterator()):\n",
    "    #x, y =  x.numpy(), y.numpy()\n",
    "    yhat = model.predict(xbatch)\n",
    "    yhats.append(yhat)\n",
    "    xs.append(xbatch)\n",
    "    ys.append(ybatch)\n",
    "xs = np.concatenate(xs, axis=0)\n",
    "ys = np.concatenate(ys, axis=0)\n",
    "yhats = np.concatenate(yhats)\n",
    "assert ys.shape == yhats.shape\n",
    "assert xs.shape[0] == yhats.shape[0]\n",
    "\n",
    "np.savetxt(fname=f'test_inputs_10k.csv', X=xs, fmt='%.8e')\n",
    "np.savetxt(fname=f'test_targets_10k.csv', X=ys, fmt='%.8e')\n",
    "np.savetxt(fname=f'test_predictions_10k.csv', X=yhats, fmt='%.8e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, yhats = [], []\n",
    "for i in range(1):\n",
    "    #x, y =  x.numpy(), y.numpy()\n",
    "    xbatch = np.random.rand(2000, 7)\n",
    "    yhat = model.predict(xbatch)\n",
    "    yhats.append(yhat)\n",
    "    xs.append(xbatch)\n",
    "yhats = np.concatenate(yhats)\n",
    "xs = np.concatenate(xs, axis=0)\n",
    "\n",
    "np.savetxt(fname=f'random_uniform_X.csv', X=xs, fmt='%.8e')\n",
    "np.savetxt(fname=f'random_uniform_Yhat.csv', X=yhats, fmt='%.8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae1dbb1a5e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(yhats[0,:], label='NN Prediction')\n",
    "plt.plot(ys[0,:], label='Target')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 - 35s - l2_regularization_loss: 0.0014 - loss: 0.0486 - mean_squared_error_loss: 0.0473 - val_l2_regularization_loss: 7.7867e-04 - val_loss: 8.1515e-04 - val_mean_squared_error_loss: 3.6481e-05\n",
      "Epoch 2/50\n",
      "10000/10000 - 16s - l2_regularization_loss: 3.6103e-04 - loss: 4.5157e-04 - mean_squared_error_loss: 9.0536e-05 - val_l2_regularization_loss: 9.0941e-05 - val_loss: 1.0680e-04 - val_mean_squared_error_loss: 1.5855e-05\n",
      "Epoch 3/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 4.6915e-05 - loss: 9.8100e-05 - mean_squared_error_loss: 5.1186e-05 - val_l2_regularization_loss: 3.0342e-05 - val_loss: 4.1476e-05 - val_mean_squared_error_loss: 1.1133e-05\n",
      "Epoch 4/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.6605e-05 - loss: 6.8386e-05 - mean_squared_error_loss: 4.1780e-05 - val_l2_regularization_loss: 2.4591e-05 - val_loss: 3.4421e-05 - val_mean_squared_error_loss: 9.8307e-06\n",
      "Epoch 5/50\n",
      "10000/10000 - 17s - l2_regularization_loss: 2.4137e-05 - loss: 6.1637e-05 - mean_squared_error_loss: 3.7501e-05 - val_l2_regularization_loss: 2.4068e-05 - val_loss: 3.4062e-05 - val_mean_squared_error_loss: 9.9941e-06\n",
      "Epoch 6/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.4326e-05 - loss: 5.9048e-05 - mean_squared_error_loss: 3.4721e-05 - val_l2_regularization_loss: 2.4672e-05 - val_loss: 3.4292e-05 - val_mean_squared_error_loss: 9.6199e-06\n",
      "Epoch 7/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.5099e-05 - loss: 5.7918e-05 - mean_squared_error_loss: 3.2819e-05 - val_l2_regularization_loss: 2.5523e-05 - val_loss: 3.5291e-05 - val_mean_squared_error_loss: 9.7673e-06\n",
      "Epoch 8/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.5912e-05 - loss: 5.7330e-05 - mean_squared_error_loss: 3.1417e-05 - val_l2_regularization_loss: 2.6287e-05 - val_loss: 3.5971e-05 - val_mean_squared_error_loss: 9.6839e-06\n",
      "Epoch 9/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.6580e-05 - loss: 5.6992e-05 - mean_squared_error_loss: 3.0412e-05 - val_l2_regularization_loss: 2.6884e-05 - val_loss: 3.8472e-05 - val_mean_squared_error_loss: 1.1587e-05\n",
      "Epoch 10/50\n",
      "10000/10000 - 17s - l2_regularization_loss: 2.7109e-05 - loss: 5.6835e-05 - mean_squared_error_loss: 2.9727e-05 - val_l2_regularization_loss: 2.7339e-05 - val_loss: 3.7177e-05 - val_mean_squared_error_loss: 9.8384e-06\n",
      "Epoch 11/50\n",
      "10000/10000 - 15s - l2_regularization_loss: 2.7530e-05 - loss: 5.6774e-05 - mean_squared_error_loss: 2.9243e-05 - val_l2_regularization_loss: 2.7690e-05 - val_loss: 3.8015e-05 - val_mean_squared_error_loss: 1.0325e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Augment to help smooth out function.\n",
    "# def add_gaussian_noise(x, y):\n",
    "#     # x must be scaled in [0, 1]\n",
    "#     with tf.name_scope('Add_gaussian_noise'):\n",
    "#         noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=.1, dtype=tf.float32)\n",
    "#         noise_x = x + noise\n",
    "#         noise_x = tf.clip_by_value(noise_x, 0.0, 1.0)\n",
    "#     return noise_x, y\n",
    "# train = train.map(add_gaussian_noise)\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #initializer = elegy.initializers.RandomNormal(stddev=.001)\n",
    "        initializer = None #elegy.initializers.TruncatedNormal()\n",
    "        x = elegy.nn.Linear(1024, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.5)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(1024, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.2)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(245, w_init=initializer, b_init=initializer)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=[elegy.losses.MeanSquaredError(),\n",
    "          #elegy.losses.MeanAbsoluteError(),\n",
    "          elegy.regularizers.GlobalL2(l=1e-6),\n",
    "         ],\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optax.sgd(1e-10),\n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "path = 'model_2_256_selu_l21e-6_do'\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_mean_squared_error_loss\", patience=5),\n",
    "             elegy.callbacks.ModelCheckpoint(path=path, save_best_only=True, monitor='val_mean_squared_error_loss'),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10000, #10000, # 10k*128 is approximate size of training set.\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "#model.save('model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 - 92s - l2_regularization_loss: 0.0027 - loss: 0.0461 - mean_squared_error_loss: 0.0434 - val_l2_regularization_loss: 0.0015 - val_loss: 0.0016 - val_mean_squared_error_loss: 6.8449e-05\n",
      "Epoch 2/50\n",
      "10000/10000 - 87s - l2_regularization_loss: 7.3936e-04 - loss: 9.3048e-04 - mean_squared_error_loss: 1.9112e-04 - val_l2_regularization_loss: 2.5369e-04 - val_loss: 2.7350e-04 - val_mean_squared_error_loss: 1.9814e-05\n",
      "Epoch 3/50\n",
      "10000/10000 - 84s - l2_regularization_loss: 1.2334e-04 - loss: 2.5761e-04 - mean_squared_error_loss: 1.3427e-04 - val_l2_regularization_loss: 6.1770e-05 - val_loss: 8.3680e-05 - val_mean_squared_error_loss: 2.1910e-05\n",
      "Epoch 4/50\n",
      "10000/10000 - 87s - l2_regularization_loss: 4.4561e-05 - loss: 1.6480e-04 - mean_squared_error_loss: 1.2024e-04 - val_l2_regularization_loss: 3.3528e-05 - val_loss: 5.6325e-05 - val_mean_squared_error_loss: 2.2796e-05\n",
      "Epoch 5/50\n",
      "10000/10000 - 78s - l2_regularization_loss: 2.8716e-05 - loss: 1.4204e-04 - mean_squared_error_loss: 1.1332e-04 - val_l2_regularization_loss: 2.5390e-05 - val_loss: 4.6950e-05 - val_mean_squared_error_loss: 2.1560e-05\n",
      "Epoch 6/50\n",
      "10000/10000 - 76s - l2_regularization_loss: 2.3717e-05 - loss: 1.3394e-04 - mean_squared_error_loss: 1.1023e-04 - val_l2_regularization_loss: 2.2427e-05 - val_loss: 4.2635e-05 - val_mean_squared_error_loss: 2.0209e-05\n",
      "Epoch 7/50\n",
      "10000/10000 - 83s - l2_regularization_loss: 2.2066e-05 - loss: 1.3028e-04 - mean_squared_error_loss: 1.0822e-04 - val_l2_regularization_loss: 2.1854e-05 - val_loss: 3.9159e-05 - val_mean_squared_error_loss: 1.7306e-05\n",
      "Epoch 8/50\n",
      "10000/10000 - 83s - l2_regularization_loss: 2.1642e-05 - loss: 1.2875e-04 - mean_squared_error_loss: 1.0711e-04 - val_l2_regularization_loss: 2.1558e-05 - val_loss: 4.3574e-05 - val_mean_squared_error_loss: 2.2016e-05\n",
      "Epoch 9/50\n",
      "10000/10000 - 77s - l2_regularization_loss: 2.1698e-05 - loss: 1.2777e-04 - mean_squared_error_loss: 1.0607e-04 - val_l2_regularization_loss: 2.1767e-05 - val_loss: 3.8335e-05 - val_mean_squared_error_loss: 1.6567e-05\n",
      "Epoch 10/50\n",
      "10000/10000 - 83s - l2_regularization_loss: 2.1912e-05 - loss: 1.2743e-04 - mean_squared_error_loss: 1.0552e-04 - val_l2_regularization_loss: 2.2011e-05 - val_loss: 3.5910e-05 - val_mean_squared_error_loss: 1.3899e-05\n",
      "Epoch 11/50\n",
      "10000/10000 - 79s - l2_regularization_loss: 2.2177e-05 - loss: 1.2759e-04 - mean_squared_error_loss: 1.0541e-04 - val_l2_regularization_loss: 2.2283e-05 - val_loss: 3.8198e-05 - val_mean_squared_error_loss: 1.5915e-05\n",
      "Epoch 12/50\n",
      "10000/10000 - 82s - l2_regularization_loss: 2.2465e-05 - loss: 1.2721e-04 - mean_squared_error_loss: 1.0474e-04 - val_l2_regularization_loss: 2.2718e-05 - val_loss: 4.4487e-05 - val_mean_squared_error_loss: 2.1769e-05\n",
      "Epoch 13/50\n",
      "10000/10000 - 82s - l2_regularization_loss: 2.2762e-05 - loss: 1.2714e-04 - mean_squared_error_loss: 1.0438e-04 - val_l2_regularization_loss: 2.2955e-05 - val_loss: 3.8159e-05 - val_mean_squared_error_loss: 1.5205e-05\n",
      "Epoch 14/50\n",
      "10000/10000 - 84s - l2_regularization_loss: 2.3002e-05 - loss: 1.2710e-04 - mean_squared_error_loss: 1.0409e-04 - val_l2_regularization_loss: 2.3169e-05 - val_loss: 3.7496e-05 - val_mean_squared_error_loss: 1.4326e-05\n",
      "Epoch 15/50\n",
      "10000/10000 - 79s - l2_regularization_loss: 2.3229e-05 - loss: 1.2704e-04 - mean_squared_error_loss: 1.0381e-04 - val_l2_regularization_loss: 2.3423e-05 - val_loss: 3.8524e-05 - val_mean_squared_error_loss: 1.5101e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Augment to help smooth out function.\n",
    "def add_gaussian_noise(x, y):\n",
    "    # x must be scaled in [0, 1]\n",
    "    with tf.name_scope('Add_gaussian_noise'):\n",
    "        noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=.1, dtype=tf.float32)\n",
    "        noise_x = x + noise\n",
    "        noise_x = tf.clip_by_value(noise_x, 0.0, 1.0)\n",
    "    return noise_x, y\n",
    "train = train.map(add_gaussian_noise)\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #initializer = elegy.initializers.RandomNormal(stddev=.001)\n",
    "        initializer = None #elegy.initializers.TruncatedNormal()\n",
    "        x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.5)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.2)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(245, w_init=initializer, b_init=initializer)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=[elegy.losses.MeanSquaredError(),\n",
    "          #elegy.losses.MeanAbsoluteError(),\n",
    "          elegy.regularizers.GlobalL2(l=1e-6),\n",
    "         ],\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optax.sgd(1e-10),\n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "path = 'model_2_256_selu_l21e-6_do_aug'\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_mean_squared_error_loss\", patience=5),\n",
    "             elegy.callbacks.ModelCheckpoint(path=path, save_best_only=True, monitor='val_mean_squared_error_loss'),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10000, #10000, # 10k*128 is approximate size of training set.\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "#model.save('model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3064977287.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_137749/3064977287.py\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/X_minmax')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/Y_logp1_scaled')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Augment to help smooth out function.\n",
    "def add_gaussian_noise(x, y):\n",
    "    # x must be scaled in [0, 1]\n",
    "    with tf.name_scope('Add_gaussian_noise'):\n",
    "        noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=.1, dtype=tf.float32)\n",
    "        noise_x = x + noise\n",
    "        noise_x = tf.clip_by_value(noise_x, 0.0, 1.0)\n",
    "    return noise_x, y\n",
    "train = train.map(add_gaussian_noise)\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #initializer = elegy.initializers.RandomNormal(stddev=.001)\n",
    "        initializer = None #elegy.initializers.TruncatedNormal()\n",
    "        x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.5)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.2)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(2048, w_init=initializer, b_init=initializer)(x)\n",
    "        x = jax.nn.selu(x)\n",
    "        x = elegy.nn.Dropout(0.1)(x)\n",
    "        \n",
    "        x = elegy.nn.Linear(245, w_init=initializer, b_init=initializer)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=[elegy.losses.MeanSquaredError(),\n",
    "          #elegy.losses.MeanAbsoluteError(),\n",
    "          elegy.regularizers.GlobalL2(l=1e-6),\n",
    "         ],\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optax.sgd(1e-10),\n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "path = 'model_3_2048_selu_l21e-6_do_aug'\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_mean_squared_error_loss\", patience=10),\n",
    "             elegy.callbacks.ModelCheckpoint(path=path, save_best_only=True, monitor='val_mean_squared_error_loss'),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10000, #10000, # 10k*128 is approximate size of training set.\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "#model.save('model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nn_hmc_elegy_oryx.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
