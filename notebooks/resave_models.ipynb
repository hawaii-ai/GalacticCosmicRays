{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66abd003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:35:40.369627: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-18 14:35:40.369676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-18 14:35:40.371232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-18 14:35:40.386049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-18 14:35:42.133835: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-09-18 14:35:47.030345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6638 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# --- OLD WORLD (tf.keras) ---\n",
    "import os, sys\n",
    "from tensorflow import keras as tfk\n",
    "\n",
    "from rtdl_num_embeddings_tf_old import (\n",
    "    LinearEmbeddings,\n",
    "    LinearReLUEmbeddings,\n",
    "    PeriodicEmbeddings,\n",
    ")\n",
    "\n",
    "old_path = \"../../models/model_size_investigation_optuna_09122025_wrongkeras\"\n",
    "old_name = \"data_d1_bootstrap_b1_model_init1_train_size_0.1_neg.keras\"\n",
    "old = tfk.models.load_model(\n",
    "    os.path.join(old_path, old_name),\n",
    "    custom_objects={\n",
    "        \"LinearEmbeddings\": LinearEmbeddings,\n",
    "        \"LinearReLUEmbeddings\": LinearReLUEmbeddings,\n",
    "        \"PeriodicEmbeddings\": PeriodicEmbeddings,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4783cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"data_d1_bootstrap_b1_model_init1_train_size_0.1_neg.weights.h5\"\n",
    "old.save_weights(os.path.join(old_path, weights_path))   # writes HDF5 weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000580c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with embedding linear_relu, 6 layers, 4096 units per layer, embed_dim 12, and n_bins 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ linear_re_lu_embeddings         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LinearReLUEmbeddings</span>)          │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">397,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,104</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ linear_re_lu_embeddings         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │        \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mLinearReLUEmbeddings\u001b[0m)          │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │    \u001b[38;5;34m397,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │    \u001b[38;5;34m131,104\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,435,168</span> (322.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,435,168\u001b[0m (322.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,435,168</span> (322.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,435,168\u001b[0m (322.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- NEW WORLD (Keras 3 / keras-core) ---\n",
    "import os\n",
    "os.environ.pop(\"KERAS_BACKEND\", None)  # or set to \"jax\"/\"tensorflow\"/\"torch\" explicitly\n",
    "import keras_core as keras\n",
    "\n",
    "# import the Keras-3 versions of the layers\n",
    "from rtdl_num_embeddings_tf import (\n",
    "    LinearEmbeddings as LinearEmbeddings,\n",
    "    LinearReLUEmbeddings as LinearReLUEmbeddings,\n",
    "    PeriodicEmbeddings as PeriodicEmbeddings,\n",
    ")\n",
    "\n",
    "def build_model(input_dim, n_layers, units, embedding_method, embed_dim=12, n_bins=48):\n",
    "    print(f\"Building model with embedding {embedding_method}, {n_layers} layers, {units} units per layer, embed_dim {embed_dim}, and n_bins {n_bins}\")\n",
    "\n",
    "    model = keras.Sequential([keras.Input(shape=(input_dim,), dtype=\"float32\")])\n",
    "\n",
    "    # Tabular embedding layer\n",
    "    if embedding_method == \"linear\":\n",
    "        model.add(LinearEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    elif embedding_method == \"linear_relu\":\n",
    "        model.add(LinearReLUEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    elif embedding_method == \"periodic\":\n",
    "        # Defaults: k=64, sigma=0.02, activation=True (you can change)\n",
    "        model.add(PeriodicEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    else:\n",
    "        # No embedding, use raw inputs\n",
    "        pass\n",
    "\n",
    "    # If you’re using SELU, pair with lecun_normal + AlphaDropout (recommended for SELU)\n",
    "    for _ in range(n_layers):\n",
    "        model.add(keras.layers.Dense(units, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation=\"linear\"))\n",
    "    return model\n",
    "\n",
    "# Set these to your actual hyperparameters\n",
    "n_layers = 6\n",
    "n_units = 4096\n",
    "embedding_method = \"linear_relu\"  # \"none\", \"linear_relu\", \"periodic\", \"piecewise_linear_relu\"\n",
    "embed_dim = 12\n",
    "n_bins = 48\n",
    "\n",
    "new = build_model(\n",
    "        input_dim=8,\n",
    "        n_layers=n_layers, \n",
    "        units=n_units,\n",
    "        embedding_method=embedding_method,\n",
    "        embed_dim=embed_dim,\n",
    "        n_bins=n_bins\n",
    "    )\n",
    "new.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a471a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Keras 3 will match by name/shape for H5 weights\n",
    "status = new.load_weights(os.path.join(old_path, weights_path), skip_mismatch=False)\n",
    "print(status)  # optional; shows matched variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de3e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OLD (tf.keras) variable names ---\n",
      "linear_re_lu_embeddings/linear_embeddings/weight:0 (8, 12)\n",
      "linear_re_lu_embeddings/linear_embeddings/bias:0 (8, 12)\n",
      "dense/kernel:0 (96, 4096)\n",
      "dense/bias:0 (4096,)\n",
      "dense_1/kernel:0 (4096, 4096)\n",
      "dense_1/bias:0 (4096,)\n",
      "dense_2/kernel:0 (4096, 4096)\n",
      "dense_2/bias:0 (4096,)\n",
      "dense_3/kernel:0 (4096, 4096)\n",
      "dense_3/bias:0 (4096,)\n",
      "dense_4/kernel:0 (4096, 4096)\n",
      "dense_4/bias:0 (4096,)\n",
      "dense_5/kernel:0 (4096, 4096)\n",
      "dense_5/bias:0 (4096,)\n",
      "dense_6/kernel:0 (4096, 32)\n",
      "dense_6/bias:0 (32,)\n",
      "\n",
      "--- NEW (keras3) variable names ---\n",
      "weight (8, 12)\n",
      "bias (8, 12)\n",
      "kernel (96, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 4096)\n",
      "bias (4096,)\n",
      "kernel (4096, 32)\n",
      "bias (32,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- OLD (tf.keras) variable names ---\")\n",
    "for v in old.weights:\n",
    "    print(v.name, v.shape)\n",
    "\n",
    "print(\"\\n--- NEW (keras3) variable names ---\")\n",
    "for v in new.weights:\n",
    "    print(v.name, v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826595ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in new: ['dense/bias:0', 'dense/kernel:0', 'dense_1/bias:0', 'dense_1/kernel:0', 'dense_2/bias:0', 'dense_2/kernel:0', 'dense_3/bias:0', 'dense_3/kernel:0', 'dense_4/bias:0', 'dense_4/kernel:0', 'dense_5/bias:0', 'dense_5/kernel:0', 'dense_6/bias:0', 'dense_6/kernel:0', 'linear_re_lu_embeddings/linear_embeddings/bias:0', 'linear_re_lu_embeddings/linear_embeddings/weight:0']\n",
      "Mismatched: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:42:00.680983: I external/local_xla/xla/service/service.cc:168] XLA service 0x8e29a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-18 14:42:00.681008: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-09-18 14:42:00.689633: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-18 14:42:00.737505: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |Δ| = 3.874302e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758242521.174109  621717 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1758242521.183270  621717 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compare_weights(old_model, new_model, atol=1e-6, rtol=1e-6):\n",
    "    # backend-agnostic to-numpy\n",
    "    try:\n",
    "        from keras_core import ops as kops\n",
    "        to_np = lambda v: kops.convert_to_numpy(v)\n",
    "    except Exception:\n",
    "        to_np = lambda v: v.numpy()\n",
    "\n",
    "    old = {w.name: to_np(w) for w in old_model.weights}\n",
    "    new = {w.name: to_np(w) for w in new_model.weights}\n",
    "\n",
    "    missing = sorted(set(old) - set(new))\n",
    "    diffs = []\n",
    "    for name in sorted(set(old) & set(new)):\n",
    "        a, b = old[name], new[name]\n",
    "        if not np.allclose(a, b, atol=atol, rtol=rtol):\n",
    "            diffs.append((name, a.shape, float(np.max(np.abs(a-b)))))\n",
    "\n",
    "    return missing, diffs\n",
    "\n",
    "missing, diffs = compare_weights(old, new)\n",
    "print(\"Missing in new:\", missing)\n",
    "print(\"Mismatched:\", diffs[:5])  # show a few if any\n",
    "\n",
    "x = np.random.randn(8, old.input_shape[-1]).astype(\"float32\")\n",
    "y_old = old.predict(x, verbose=0)\n",
    "y_new = new.predict(x, verbose=0)\n",
    "print(\"max |Δ| =\", np.max(np.abs(y_old - y_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62f45fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = \"data_d1_bootstrap_b1_model_init1_train_size_0.1_neg.keras\"\n",
    "new_weights_path = \"../../models/model_size_investigation_optuna_09122025\"\n",
    "new.save(os.path.join(new_weights_path, new_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c94eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linneamw/anaconda3/envs/gcr-gpu/lib/python3.9/site-packages/keras_core/src/layers/layer.py:355: UserWarning: `build()` was called on layer 'linear_re_lu_embeddings', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ linear_re_lu_embeddings         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LinearReLUEmbeddings</span>)          │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">397,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)              │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,104</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ linear_re_lu_embeddings         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │        \u001b[38;5;34m192\u001b[0m │\n",
       "│ (\u001b[38;5;33mLinearReLUEmbeddings\u001b[0m)          │                           │            │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │    \u001b[38;5;34m397,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)              │ \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │    \u001b[38;5;34m131,104\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,435,168</span> (322.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,435,168\u001b[0m (322.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,435,168</span> (322.09 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,435,168\u001b[0m (322.09 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import keras_core as keras\n",
    "from rtdl_num_embeddings_tf import (\n",
    "    LinearEmbeddings as LinearEmbeddings,\n",
    "    LinearReLUEmbeddings as LinearReLUEmbeddings,\n",
    "    PeriodicEmbeddings as PeriodicEmbeddings,\n",
    ")\n",
    "new_weights_path = \"../../models/model_size_investigation_optuna_09122025\"\n",
    "new_path = \"data_d1_bootstrap_b1_model_init1_train_size_0.1_neg.keras\"\n",
    "\n",
    "new2 = keras.models.load_model(os.path.join(new_weights_path, new_path))\n",
    "new2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc50f6",
   "metadata": {},
   "source": [
    "# Now let's do it for every file in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ecfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 15:20:33.716655: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-18 15:20:33.716688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-18 15:20:33.718205: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-18 15:20:33.726799: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-18 15:20:35.084236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow import keras as tfk\n",
    "from rtdl_num_embeddings_tf_old import LinearEmbeddings as LinearEmbeddings_old\n",
    "from rtdl_num_embeddings_tf_old import LinearReLUEmbeddings as LinearReLUEmbeddings_old\n",
    "from rtdl_num_embeddings_tf_old import PeriodicEmbeddings as PeriodicEmbeddings_old\n",
    "\n",
    "os.environ.pop(\"KERAS_BACKEND\", None)  # or set to \"jax\"/\"tensorflow\"/\"torch\" explicitly\n",
    "import keras_core as keras\n",
    "\n",
    "# import the Keras-3 versions of the layers\n",
    "from rtdl_num_embeddings_tf import (\n",
    "    LinearEmbeddings as LinearEmbeddings,\n",
    "    LinearReLUEmbeddings as LinearReLUEmbeddings,\n",
    "    PeriodicEmbeddings as PeriodicEmbeddings,\n",
    ")\n",
    "\n",
    "def build_model(input_dim, n_layers, units, embedding_method, embed_dim=12, n_bins=48):\n",
    "    print(f\"Building model with embedding {embedding_method}, {n_layers} layers, {units} units per layer, embed_dim {embed_dim}, and n_bins {n_bins}\")\n",
    "\n",
    "    model = keras.Sequential([keras.Input(shape=(input_dim,), dtype=\"float32\")])\n",
    "\n",
    "    # Tabular embedding layer\n",
    "    if embedding_method == \"linear\":\n",
    "        model.add(LinearEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    elif embedding_method == \"linear_relu\":\n",
    "        model.add(LinearReLUEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    elif embedding_method == \"periodic\":\n",
    "        # Defaults: k=64, sigma=0.02, activation=True (you can change)\n",
    "        model.add(PeriodicEmbeddings(input_dim, embed_dim))\n",
    "        model.add(keras.layers.Flatten())\n",
    "    else:\n",
    "        # No embedding, use raw inputs\n",
    "        pass\n",
    "\n",
    "    # If you’re using SELU, pair with lecun_normal + AlphaDropout (recommended for SELU)\n",
    "    for _ in range(n_layers):\n",
    "        model.add(keras.layers.Dense(units, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ff730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data_d1_bootstrap_b1_model_init2_train_size_0.1_neg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 15:20:38.357968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6638 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with embedding linear_relu, 6 layers, 4096 units per layer, embed_dim 12, and n_bins 48\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 15:21:20.136104: I external/local_xla/xla/service/service.cc:168] XLA service 0x829f160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-18 15:21:20.136133: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-09-18 15:21:20.144805: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-18 15:21:20.164769: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758244880.537802  629841 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1758244880.545791  629841 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |Δ| = 5.9604645e-07\n",
      "\n",
      "Processing data_d1_bootstrap_b1_model_init2_train_size_0.3_neg...\n",
      "Building model with embedding linear_relu, 6 layers, 4096 units per layer, embed_dim 12, and n_bins 48\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758244922.457933  629839 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |Δ| = 4.172325e-07\n",
      "\n",
      "Processing data_d1_bootstrap_b1_model_init2_train_size_0.5_neg...\n",
      "Building model with embedding linear_relu, 6 layers, 4096 units per layer, embed_dim 12, and n_bins 48\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758244963.778621  629838 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |Δ| = 4.7683716e-07\n",
      "\n",
      "Processing data_d1_bootstrap_b1_model_init2_train_size_0.7_neg...\n",
      "Building model with embedding linear_relu, 6 layers, 4096 units per layer, embed_dim 12, and n_bins 48\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1758245004.226229  629839 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max |Δ| = 4.172325e-07\n"
     ]
    }
   ],
   "source": [
    "datas = [\"d1\", \"d2\", \"d3\"]\n",
    "inits = [\"init1\", \"init2\", \"init3\"]\n",
    "sizes = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "old_path = \"../../models/model_size_investigation_optuna_09122025_wrongkeras\"\n",
    "new_weights_path = \"../../models/model_size_investigation_optuna_09122025\"\n",
    "\n",
    "for data in datas:\n",
    "    for init in inits:\n",
    "        for size in sizes:\n",
    "            filename = f\"data_{data}_bootstrap_b1_model_{init}_train_size_{size}_neg\"\n",
    "            print (f\"\\nProcessing {filename}...\")\n",
    "\n",
    "            old_name = filename + \".keras\"\n",
    "            old = tfk.models.load_model(\n",
    "                os.path.join(old_path, old_name),\n",
    "                custom_objects={\n",
    "                    \"LinearEmbeddings\": LinearEmbeddings_old,\n",
    "                    \"LinearReLUEmbeddings\": LinearReLUEmbeddings_old,\n",
    "                    \"PeriodicEmbeddings\": PeriodicEmbeddings_old,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            weights_path = filename + \".weights.h5\"\n",
    "            old.save_weights(os.path.join(old_path, weights_path))   # writes HDF5 weights\n",
    "            \n",
    "            # Set these to your actual hyperparameters\n",
    "            n_layers = 6\n",
    "            n_units = 4096\n",
    "            embedding_method = \"linear_relu\"  # \"none\", \"linear_relu\", \"periodic\", \"piecewise_linear_relu\"\n",
    "            embed_dim = 12\n",
    "            n_bins = 48\n",
    "\n",
    "            new = build_model(\n",
    "                input_dim=8,\n",
    "                n_layers=n_layers, \n",
    "                units=n_units,\n",
    "                embedding_method=embedding_method,\n",
    "                embed_dim=embed_dim,\n",
    "                n_bins=n_bins\n",
    "            )\n",
    "\n",
    "            status = new.load_weights(os.path.join(old_path, weights_path), skip_mismatch=False)\n",
    "            print(status)  # optional; shows matched variables\n",
    "\n",
    "            x = np.random.randn(8, old.input_shape[-1]).astype(\"float32\")\n",
    "            y_old = old.predict(x, verbose=0)\n",
    "            y_new = new.predict(x, verbose=0)\n",
    "            print(\"max |Δ| =\", np.max(np.abs(y_old - y_new)))\n",
    "\n",
    "            new_path = filename + \".keras\"\n",
    "            new.save(os.path.join(new_weights_path, new_path))\n",
    "\n",
    "            del old, new, y_old, y_new, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fe86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcr-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
