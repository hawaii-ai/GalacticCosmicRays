{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de89b550-d2d0-4d85-9952-94add46db167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training NN with Elegy then do HMC with Oryx on Mana\n",
    "# Author: Peter Oct 24 2021\n",
    "# Requirements: \n",
    "#!module load system/CUDA/11.0.2 \n",
    "#!pip install --upgrade jax jaxlib==0.1.68+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html \n",
    "#!pip install tensorflow-io oryx elegy\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "#os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "#os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.10'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import vmap\n",
    "from jax import jit\n",
    "from jax import grad\n",
    "\n",
    "assert jax.default_backend() == 'gpu'\n",
    "\n",
    "import oryx  # pip install oryx\n",
    "import elegy # pip install elegy\n",
    "import optax\n",
    "#import flax.linen\n",
    "import tensorflow_io as tfio # pip install tensorflow-io\n",
    "import tensorflow as tf # Recommended not to import this with jax because will also try to grab memory.\n",
    "\n",
    "tfd = oryx.distributions\n",
    "state = oryx.core.state\n",
    "ppl = oryx.core.ppl\n",
    "inverse = oryx.core.inverse\n",
    "ildj = oryx.core.ildj\n",
    "plant = oryx.core.plant\n",
    "reap = oryx.core.reap\n",
    "sow = oryx.core.sow\n",
    "unzip = oryx.core.unzip\n",
    "nn = oryx.experimental.nn\n",
    "mcmc = oryx.experimental.mcmc\n",
    "optimizers = oryx.experimental.optimizers # Oryx based on https://github.com/deepmind/optax\n",
    "\n",
    "def load_data_ams():\n",
    "    \"\"\" Load AMS data from Claudio.\"\"\"\n",
    "    filename = '../data/BR2461.dat'\n",
    "    alpha, cmf = 69.19, 5.17 # These are fixed for the current experiment.\n",
    "    dataset_ams = np.loadtxt(filename) # Rigidity1, Rigidity2, Flux, Error\n",
    "    r1, r2 = dataset_ams[:,0], dataset_ams[:,1]\n",
    "    bins = np.concatenate([r1[:], r2[-1:]])\n",
    "    observed = dataset_ams[:,2]   # Observed Flux\n",
    "    uncertainty = dataset_ams[:,3]\n",
    "    assert len(bins) == len(observed)+1\n",
    "    return bins, observed, uncertainty, alpha, cmf\n",
    "\n",
    "def load_preprocessed_data_ams():\n",
    "    \"\"\" Load AMS data along with hardcoded auxiliary vectors for ppmodel.\"\"\"\n",
    "    bins, observed, uncertainty, alpha, cmf = load_data_ams()\n",
    "    if False:\n",
    "        pass\n",
    "        # Need to compute this once and then hardcode results.\n",
    "        #xloc = np.sort(np.concatenate([jnp.arange(245), bins+1e-12])) # Both the lattice and the given bins. Add epsilon to bin to distinguish it; shouldn't affect result.\n",
    "        #iloc = jnp.where(xloc % 1 > 0)[0] # Throws error https://github.com/google/jax/issues/4309. Just hardcode result as a quick workaround.\n",
    "        #print(iloc) # Hardcode this below to make JAX happy. \n",
    "    else:\n",
    "        # Hardcode a list containing the lattice of range(245) and bin edges from the AMS data.\n",
    "        xloc = jnp.sort(jnp.concatenate([jnp.arange(245), bins])) \n",
    "        # Hardcode the indices of the AMS bin edges in this list, so that we can integrate between them.\n",
    "        iloc = [  2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  14,  15,\n",
    "                      17,  18,  19,  21,  22,  24,  26,  27,  29,  31,  33,  35,\n",
    "                      37,  39,  41,  43,  45,  48,  50,  53,  55,  58,  61,  64,\n",
    "                      68,  71,  75,  78,  82,  87,  91,  96, 101, 106]\n",
    "        #slices = [slice(iloc[i], iloc[i+1]) for i in range(45)] # These are the slices for each bin.\n",
    "    return xloc, iloc, observed, uncertainty, alpha, cmf\n",
    "\n",
    "def define_ppmodel(model, xloc, iloc, observed, uncertainty, alpha_norm, cmf_norm):\n",
    "    ''' \n",
    "    Defines a probabilistic program model from NN and data.\n",
    "    Inputs:\n",
    "        model = NN from elegy\n",
    "        xloc =\n",
    "        iloc =\n",
    "        observed =\n",
    "    Returns:\n",
    "        jax probalistic program\n",
    "    '''\n",
    "    def ppmodel(key):\n",
    "        \"\"\" \n",
    "        Define probabilistic programming model as a random sample from input space, \n",
    "        then application of NN, then computation of likelihood.\n",
    "        \"\"\"\n",
    "        # First sample from 7-D gaussian prior.\n",
    "        #x = ppl.random_variable(tfd.MultivariateNormalDiag(jnp.zeros(7), jnp.ones(7)), name='x')(key)\n",
    "        #prior = tfd.Uniform(low=jnp.zeros(7), high=5*jnp.ones(7)) # Doesn't work.\n",
    "        # NN is trained on min-max scaled data, so inputs should be in [0,1].\n",
    "        # prior = tfd.Independent(tfd.Uniform(low=[alpha, cmf, 0., 0., 0., 0., 0.],\n",
    "        #                                     high=[alpha, cmf, 1., 1., 1., 1., 1.]), \n",
    "        #                                     validate_args=True, reinterpreted_batch_ndims=1) # This doesn't work because all proposals rejected in hmc.\n",
    "        prior = tfd.Sample(tfd.Uniform(0., 1.), sample_shape=(5,))\n",
    "        x = ppl.random_variable(prior, name='x')\n",
    "        x = x(key) # Sample from 5-dimensional space.\n",
    "        x = jnp.concatenate([jnp.array([alpha_norm, cmf_norm]), x]) # Create 7d input to NN.\n",
    "\n",
    "        # Apply NN and get predicted flux on 245 lattice points.\n",
    "        yhat = model.predict(x) # Reminder: model should be in eager mode. \n",
    "        yhat = jnp.exp(yhat) - 1. # Undo logp1 transform of target output. \n",
    "        # Interpolate to get predicted flux at both lattice and bin points.\n",
    "        yloc = jnp.interp(xloc, jnp.arange(245), yhat) \n",
    "        # Integrate over bin regions, and compare to observed to get likelihood.\n",
    "        loglikelihood = 0.0\n",
    "        for i in range(45):\n",
    "            # Integrate over bin by trapezoid method.\n",
    "            predicted : float = jnp.trapz(yloc[iloc[i]:iloc[i+1]], x=xloc[iloc[i]:iloc[i+1]])\n",
    "            # Use equation provided by Claudio for likelihood of bin.\n",
    "            bin_loglikelihood = ((predicted - observed[i])/uncertainty[i])**2\n",
    "            # Sum to get joint loglikelihood.\n",
    "            loglikelihood += bin_loglikelihood\n",
    "        return jnp.exp(loglikelihood) # Oryx expects likelihood.\n",
    "    return ppmodel\n",
    "\n",
    "def remove_consecutive_duplicates(X):\n",
    "    ''' \n",
    "    Remove consecutive duplicate rows from array. This means sample from MCMC was rejected.\n",
    "    Input:\n",
    "        X = 2d array, where each row is a sample\n",
    "    Returns:\n",
    "        rval = 2d array with consecutive duplicate rows removed\n",
    "    '''\n",
    "    consecutive_repeat_rows = np.all(samples[:-1,:] == samples[1:,:], axis=1)\n",
    "    return X[~consecutive_repeat_rows, :]\n",
    "\n",
    "# Load trained NN model that maps 7 parameters to predicted flux at rigidity vals range(245).\n",
    "model = elegy.load('my_model')\n",
    "model.run_eagerly = True # Settable attribute. Required to be true for ppmodel.\n",
    "\n",
    "# Load observation data.\n",
    "xloc, iloc, observed, uncertainty, alpha, cmf = load_preprocessed_data_ams()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af91c7d-52de-4caa-beb5-f347a18bbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "num_samples = 1e6\n",
    "num_leapfrog_steps = 1e4\n",
    "step_size = 1e-6\n",
    "seed = 2\n",
    "\n",
    "# Run Hamiltonian Monte Carlo\n",
    "start = 0.5*jnp.ones(5) # This is the starting state for MCMC.\n",
    "alpha_norm = (alpha - 20.) / 55. # Min max scaling\n",
    "cmf_norm = (cmf - 4.5) / 4. # Min max scaling\n",
    "ppmodel = define_ppmodel(model, xloc, iloc, observed, uncertainty, alpha_norm, cmf_norm)\n",
    "hmc = mcmc.hmc(ppl.joint_log_prob(ppmodel),\n",
    "               num_leapfrog_steps = num_leapfrog_steps, # Too low and samples will be correlated.\n",
    "               step_size = step_size) # Too high and proposals won't be accepted. \n",
    "# Experiments:\n",
    "# N=samples, L=num_leapfrog_steps, e=step_size, p=repeated_states, T=Time.\n",
    "# L=1e3,e=1e-4,p=1/3. L=1e3,e=1e-5,p=0.02. L=1e3,e=1e-6,p=0.0,T=1e2sec but bad mixing.\n",
    "# L=1e4,e=1e-6,N=1e5, p=0.02,T=14min20s.\n",
    "unnormalized_samples = jit(mcmc.sample_chain(hmc, num_samples))(random.PRNGKey(seed), start) # use log_prob doesn't work because function too complex.\n",
    "unnormalized_samples = unnormalized_samples.to_py()\n",
    "\n",
    "# De-normalize samples.\n",
    "#MIN_VALS = np.array([20., 4.5, 50., 0.2, 0.2, 0.2, 0.2])\n",
    "#MAX_VALS = np.array([75., 8.5, 250., 2., 2.3, 2., 2.3])\n",
    "MIN_VALS = np.array([50., 0.2, 0.2, 0.2, 0.2])\n",
    "MAX_VALS = np.array([250., 2., 2.3, 2., 2.3])\n",
    "RANGE_VALS = MAX_VALS - MIN_VALS\n",
    "all_samples = unnormalized_samples * RANGE_VALS + MIN_VALS\n",
    "\n",
    "# Remove rejected samples. \n",
    "samples = remove_consecutive_duplicates(all_samples) \n",
    "print(f'Acceptance rate: {len(samples)/len(all_samples)}. Decrease step_size to increase rate.')\n",
    "    \n",
    "# Throw out initial samples to ensure proper mixing.\n",
    "samples = samples[np.floor(0.01 * len(samples)):, :]\n",
    "\n",
    "# Save samples.\n",
    "np.savetxt(fname=f'results/samples_{num_samples}_{num_leapfrog_steps}_{step_size}.csv', X=samples)\n",
    "\n",
    "# Plot marginals.\n",
    "parameter_names = ['cpa', 'pwr1par', 'pwr2par', 'pwr1perr', 'pwr2perr']\n",
    "plt.figure(1, figsize=(24, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.hist(samples[:, i])\n",
    "    plt.xlabel(parameter_names[i])\n",
    "    plt.xlim((MIN_VALS[i], MAX_VALS[i]))\n",
    "plt.savefig(fname=f'results/marginals_{num_samples}_{num_leapfrog_steps}_{step_size}.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jax]",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
