{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ve8yVrLbiOXv"
   },
   "outputs": [],
   "source": [
    "# Training NN with Elegy then do HMC with Oryx on Mana\n",
    "# Author: Peter Oct 24 2021\n",
    "# Requirements: \n",
    "#!module load system/CUDA/11.0.2 \n",
    "#!pip install --upgrade jax jaxlib==0.1.68+cuda110 -f https://storage.googleapis.com/jax-releases/jax_releases.html \n",
    "#!pip install tensorflow-io oryx elegy\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "import os\n",
    "#os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "#os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.10'\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import vmap\n",
    "from jax import jit\n",
    "from jax import grad\n",
    "\n",
    "assert jax.default_backend() == 'gpu'\n",
    "\n",
    "import oryx  # pip install oryx\n",
    "import elegy # pip install elegy\n",
    "import optax\n",
    "#import flax.linen\n",
    "import tensorflow_io as tfio # pip install tensorflow-io\n",
    "import tensorflow as tf # Recommended not to import this with jax because will also try to grab memory.\n",
    "\n",
    "tfd = oryx.distributions\n",
    "\n",
    "state = oryx.core.state\n",
    "ppl = oryx.core.ppl\n",
    "\n",
    "inverse = oryx.core.inverse\n",
    "ildj = oryx.core.ildj\n",
    "plant = oryx.core.plant\n",
    "reap = oryx.core.reap\n",
    "sow = oryx.core.sow\n",
    "unzip = oryx.core.unzip\n",
    "\n",
    "nn = oryx.experimental.nn\n",
    "mcmc = oryx.experimental.mcmc\n",
    "optimizers = oryx.experimental.optimizers # Oryx based on https://github.com/deepmind/optax\n",
    "#optimizer = optimizers.adam(1e-4) # Oryx based on https://github.com/deepmind/optax\n",
    "#opt_state = state.init(optimizer)(opt_key, network, network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F51vk2W66pyG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 20:13:23.880349: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n",
      "2021-10-28 20:13:24.658039: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "10000/10000 - 88s - loss: 0.2650 - mean_squared_error_loss: 0.2650 - val_loss: 1.7224e-04 - val_mean_squared_error_loss: 1.7224e-04\n",
      "Epoch 2/6\n",
      "10000/10000 - 81s - loss: 1.4207e-04 - mean_squared_error_loss: 1.4207e-04 - val_loss: 1.2932e-04 - val_mean_squared_error_loss: 1.2932e-04\n",
      "Epoch 3/6\n",
      "10000/10000 - 79s - loss: 1.2226e-04 - mean_squared_error_loss: 1.2226e-04 - val_loss: 1.3966e-04 - val_mean_squared_error_loss: 1.3966e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(245,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "f = '/mnt/lts/nfs_fs02/sadow_lab/shared/gcr/data/proposal/data_processed.hdf5'\n",
    "MEAN_VALS = np.array([41.094597, 6.4734573, 160.1557, 1.0845096, 1.3110111, 1.1005557, 1.2972884])\n",
    "MIN_VALS = np.array([20., 4.5, 50., 0.2, 0.2, 0.2, 0.2])\n",
    "MAX_VALS = np.array([75., 8.5, 250., 2., 2.3, 2., 2.3])\n",
    "RANGE_VALS = MAX_VALS - MIN_VALS\n",
    "#f = './data_processed_sample.hdf5'\n",
    "x = tfio.IODataset.from_hdf5(f, dataset='/features')\n",
    "y = tfio.IODataset.from_hdf5(f, dataset='/logp1_flux')\n",
    "full = tf.data.Dataset.zip((x, y))\n",
    "full = full.map(lambda x, y: ((x - MIN_VALS) / RANGE_VALS, y)) # Min-max scale.\n",
    "# Split\n",
    "train = full.take(np.floor(1435308 *.9)).repeat()\n",
    "test = full.skip(np.floor(1435308 *.9)).repeat()\n",
    "# Batch\n",
    "BATCH_SIZE = 128\n",
    "train = train.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test = test.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "class MLP(elegy.Module):\n",
    "    # Defines stateful model. See elegy docs.\n",
    "    # def __init__(self, scale: np.ndarray, **kwargs):\n",
    "    #     self.Scale = Scale(scale)\n",
    "    #     super().__init__(**kwargs)\n",
    "    def call(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        #x = x / MEAN_VALS # Mean-scale inputs.\n",
    "        x = elegy.nn.Linear(1024)(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = elegy.nn.Linear(1024)(x)\n",
    "        x = jax.nn.tanh(x)\n",
    "        x = elegy.nn.Linear(245)(x)\n",
    "        return x\n",
    "\n",
    "model = elegy.Model(\n",
    "    # Creates stateful model and optimizer. See elegy docs.\n",
    "    module=MLP(),\n",
    "    loss=elegy.losses.MeanSquaredError(),\n",
    "    #loss=[elegy.losses.MeanSquaredError(), elegy.regularizers.GlobalL2(l=1e-5)]\n",
    "    #metrics=elegy.metrics.BinaryAccuracy(),\n",
    "    optimizer=optax.adam(1e-4), \n",
    "    #optimizer=optimizers.rmsprop(1e-3), # Oryx based on optax. Doesn't work with elegy.\n",
    "    #run_eagerly=True, # Seems to be necessary for \n",
    ")\n",
    "\n",
    "callbacks = [elegy.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1),\n",
    "             #elegy.callbacks.TensorBoard(\"summaries\"),\n",
    "            ]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train,\n",
    "    epochs=6,\n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=test,\n",
    "    validation_steps=1000,\n",
    "    shuffle=False,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model. \n",
    "model.save('my_model')  # creates folder at 'my_model'\n",
    "#del model  # deletes the existing model\n",
    "# Test ability to make prediction.\n",
    "x = np.random.rand((7))\n",
    "model.predict(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use trained model for Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See hmc_gcr.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nn_hmc_elegy_oryx.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:jax]",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
