{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d266b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from typing import Any, Literal, Optional, Union\n",
    "\n",
    "try:\n",
    "    import sklearn.tree as sklearn_tree\n",
    "except ImportError:\n",
    "    sklearn_tree = None\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76161d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_input_shape(x: Tensor, expected_n_features: int) -> None:\n",
    "    if x.ndim < 1:\n",
    "        raise ValueError(\n",
    "            f'The input must have at least one dimension, however: {x.ndim=}'\n",
    "        )\n",
    "    if x.shape[-1] != expected_n_features:\n",
    "        raise ValueError(\n",
    "            'The last dimension of the input was expected to be'\n",
    "            f' {expected_n_features}, however, {x.shape[-1]=}'\n",
    "        )\n",
    "\n",
    "class _PiecewiseLinearEncodingImpl(nn.Module):\n",
    "    \"\"\"Piecewise-linear encoding.\n",
    "\n",
    "    NOTE: THIS CLASS SHOULD NOT BE USED DIRECTLY.\n",
    "    In particular, this class does *not* add any positional information\n",
    "    to feature encodings. Thus, for Transformer-like models,\n",
    "    `PiecewiseLinearEmbeddings` is the only valid option.\n",
    "\n",
    "    Note:\n",
    "        This is the *encoding* module, not the *embedding* module,\n",
    "        so it only implements Equation 1 (Figure 1) from the paper,\n",
    "        and does not have trainable parameters.\n",
    "\n",
    "    **Shape**\n",
    "\n",
    "    * Input: ``(*, n_features)``\n",
    "    * Output: ``(*, n_features, max_n_bins)``,\n",
    "      where ``max_n_bins`` is the maximum number of bins over all features:\n",
    "      ``max_n_bins = max(len(b) - 1 for b in bins)``.\n",
    "\n",
    "    To understand the output structure,\n",
    "    consider a feature with the number of bins ``n_bins``.\n",
    "    Formally, its piecewise-linear encoding is a vector of the size ``n_bins``\n",
    "    that looks as follows::\n",
    "\n",
    "        x_ple = [1, ..., 1, (x - this_bin_left_edge) / this_bin_width, 0, ..., 0]\n",
    "\n",
    "    However, this class will instead produce a vector of the size ``max_n_bins``::\n",
    "\n",
    "        x_ple_actual = [*x_ple[:-1], *zeros(max_n_bins - n_bins), x_ple[-1]]\n",
    "\n",
    "    In other words:\n",
    "\n",
    "    * The last encoding component is **always** located in the end,\n",
    "      even if ``n_bins == 1`` (i.e. even if it is the only component).\n",
    "    * The leading ``n_bins - 1`` components are located in the beginning.\n",
    "    * Everything in-between is always set to zeros (like \"padding\", but in the middle).\n",
    "\n",
    "    This implementation is *significantly* faster than the original one.\n",
    "    It relies on two key observations:\n",
    "\n",
    "    * The piecewise-linear encoding is just\n",
    "      a non-trainable linear transformation followed by a clamp-based activation.\n",
    "      Pseudocode: `PiecewiseLinearEncoding(x) = Activation(Linear(x))`.\n",
    "      The parameters of the linear transformation are defined by the bin edges.\n",
    "    * Aligning the *last* encoding channel across all features\n",
    "      allows applying the aforementioned activation simultaneously to all features\n",
    "      without the loop over features.\n",
    "    \"\"\"\n",
    "\n",
    "    weight: Tensor\n",
    "    \"\"\"The weight of the linear transformation mentioned in the class docstring.\"\"\"\n",
    "\n",
    "    bias: Tensor\n",
    "    \"\"\"The bias of the linear transformation mentioned in the class docstring.\"\"\"\n",
    "\n",
    "    single_bin_mask: Optional[Tensor]\n",
    "    \"\"\"The indicators of the features with only one bin.\"\"\"\n",
    "\n",
    "    mask: Optional[Tensor]\n",
    "    \"\"\"The indicators of the \"valid\" (i.e. \"non-padding\") part of the encoding.\"\"\"\n",
    "\n",
    "    def __init__(self, bins: list[Tensor]) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bins: the bins computed by `compute_bins`.\n",
    "        \"\"\"\n",
    "        assert len(bins) > 0\n",
    "        super().__init__()\n",
    "\n",
    "        n_features = len(bins)\n",
    "        n_bins = [len(x) - 1 for x in bins]\n",
    "        max_n_bins = max(n_bins)\n",
    "\n",
    "        self.register_buffer('weight', torch.zeros(n_features, max_n_bins))\n",
    "        self.register_buffer('bias', torch.zeros(n_features, max_n_bins))\n",
    "\n",
    "        single_bin_mask = torch.tensor(n_bins) == 1\n",
    "        self.register_buffer(\n",
    "            'single_bin_mask', single_bin_mask if single_bin_mask.any() else None\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            # The mask is needed if features have different number of bins.\n",
    "            None\n",
    "            if all(len(x) == len(bins[0]) for x in bins)\n",
    "            else torch.row_stack(\n",
    "                [\n",
    "                    torch.cat(\n",
    "                        [\n",
    "                            # The number of bins for this feature, minus 1:\n",
    "                            torch.ones((len(x) - 1) - 1, dtype=torch.bool),\n",
    "                            # Unused components (always zeros):\n",
    "                            torch.zeros(max_n_bins - (len(x) - 1), dtype=torch.bool),\n",
    "                            # The last bin:\n",
    "                            torch.ones(1, dtype=torch.bool),\n",
    "                        ]\n",
    "                    )\n",
    "                    # x is a tensor containing the bin bounds for a given feature.\n",
    "                    for x in bins\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        for i, bin_edges in enumerate(bins):\n",
    "            # Formally, the piecewise-linear encoding of one feature looks as follows:\n",
    "            # `[1, ..., 1, (x - this_bin_left_edge) / this_bin_width, 0, ..., 0]`\n",
    "            # The linear transformation based on the weight and bias defined below\n",
    "            # implements the expression in the middle before the clipping to [0, 1].\n",
    "            # Note that the actual encoding layout produced by this class\n",
    "            # is slightly different. See the docstring of this class for details.\n",
    "            bin_width = bin_edges.diff()\n",
    "            w = 1.0 / bin_width\n",
    "            b = -bin_edges[:-1] / bin_width\n",
    "            # The last encoding component:\n",
    "            self.weight[i, -1] = w[-1]\n",
    "            self.bias[i, -1] = b[-1]\n",
    "            # The leading encoding components:\n",
    "            self.weight[i, : n_bins[i] - 1] = w[:-1]\n",
    "            self.bias[i, : n_bins[i] - 1] = b[:-1]\n",
    "            # All in-between components will always be zeros,\n",
    "            # because the weight and bias are initialized with zeros.\n",
    "\n",
    "    def get_max_n_bins(self) -> int:\n",
    "        return self.weight.shape[-1]\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Do the forward pass.\"\"\"\n",
    "        x = torch.addcmul(self.bias, self.weight, x[..., None])\n",
    "        if x.shape[-1] > 1:\n",
    "            x = torch.cat(\n",
    "                [\n",
    "                    x[..., :1].clamp_max(1.0),\n",
    "                    x[..., 1:-1].clamp(0.0, 1.0),\n",
    "                    (\n",
    "                        x[..., -1:].clamp_min(0.0)\n",
    "                        if self.single_bin_mask is None\n",
    "                        else torch.where(\n",
    "                            # For features with only one bin,\n",
    "                            # the whole \"piecewise-linear\" encoding effectively behaves\n",
    "                            # like mix-max scaling\n",
    "                            # (assuming that the edges of the single bin\n",
    "                            #  are the minimum and maximum feature values).\n",
    "                            self.single_bin_mask[..., None],\n",
    "                            x[..., -1:],\n",
    "                            x[..., -1:].clamp_min(0.0),\n",
    "                        )\n",
    "                    ),\n",
    "                ],\n",
    "                dim=-1,\n",
    "            )\n",
    "        return x\n",
    "\n",
    "\n",
    "class PiecewiseLinearEncoding(nn.Module):\n",
    "    \"\"\"Piecewise-linear encoding.\n",
    "\n",
    "    See README for detailed explanation.\n",
    "\n",
    "    **Shape**\n",
    "\n",
    "    - Input: ``(*, n_features)``\n",
    "    - Output: ``(*, total_n_bins)``,\n",
    "      where ``total_n_bins`` is the total number of bins for all features:\n",
    "      ``total_n_bins = sum(len(b) - 1 for b in bins)``.\n",
    "\n",
    "    Technically, the output of this module is the flattened output\n",
    "    of `_PiecewiseLinearEncoding` with all \"padding\" values removed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bins: list[Tensor]) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bins: the bins computed by `compute_bins`.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.impl = _PiecewiseLinearEncodingImpl(bins)\n",
    "\n",
    "    def get_output_shape(self) -> torch.Size:\n",
    "        \"\"\"Get the output shape without the batch dimensions.\"\"\"\n",
    "        total_n_bins = (\n",
    "            self.impl.weight.shape.numel()\n",
    "            if self.impl.mask is None\n",
    "            else int(self.impl.mask.long().sum().cpu().item())\n",
    "        )\n",
    "        return torch.Size((total_n_bins,))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Do the forward pass.\"\"\"\n",
    "        x = self.impl(x)\n",
    "        return x.flatten(-2) if self.impl.mask is None else x[:, self.impl.mask]\n",
    "\n",
    "\n",
    "class PiecewiseLinearEmbeddings(nn.Module):\n",
    "    \"\"\"Piecewise-linear embeddings.\n",
    "\n",
    "    **Shape**\n",
    "\n",
    "    - Input: ``(batch_size, n_features)``\n",
    "    - Output: ``(batch_size, n_features, d_embedding)``\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        bins: list[Tensor],\n",
    "        d_embedding: int,\n",
    "        *,\n",
    "        activation: bool,\n",
    "        version: Literal[None, 'A', 'B'] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            bins: the bins computed by `compute_bins`.\n",
    "            d_embedding: the embedding size.\n",
    "            activation: if True, the ReLU activation is additionally applied in the end.\n",
    "            version: the preset for various implementation details, such as\n",
    "                parametrization and initialization. See README for details.\n",
    "        \"\"\"\n",
    "        if d_embedding <= 0:\n",
    "            raise ValueError(\n",
    "                f'd_embedding must be a positive integer, however: {d_embedding=}'\n",
    "            )\n",
    "        _check_bins(bins)\n",
    "        if version is None:\n",
    "            warnings.warn(\n",
    "                'The `version` argument is not provided, so version=\"A\" will be used'\n",
    "                ' for backward compatibility.'\n",
    "                ' See README for recommendations regarding `version`.'\n",
    "                ' In future, omitting this argument will result in an exception.'\n",
    "            )\n",
    "            version = 'A'\n",
    "\n",
    "        super().__init__()\n",
    "        n_features = len(bins)\n",
    "        # NOTE[DIFF]\n",
    "        # version=\"B\" was introduced in a different paper (about the TabM model).\n",
    "        is_version_B = version == 'B'\n",
    "\n",
    "        self.linear0 = (\n",
    "            LinearEmbeddings(n_features, d_embedding) if is_version_B else None\n",
    "        )\n",
    "        self.impl = _PiecewiseLinearEncodingImpl(bins)\n",
    "        self.linear = _NLinear(\n",
    "            len(bins),\n",
    "            self.impl.get_max_n_bins(),\n",
    "            d_embedding,\n",
    "            # For the version \"B\", the bias is already presented in self.linear0.\n",
    "            bias=not is_version_B,\n",
    "        )\n",
    "        if is_version_B:\n",
    "            # Because of the following line, at initialization,\n",
    "            # the whole embedding behaves like a linear embedding.\n",
    "            # The piecewise-linear component is incrementally learnt during training.\n",
    "            nn.init.zeros_(self.linear.weight)\n",
    "        self.activation = nn.ReLU() if activation else None\n",
    "\n",
    "    def get_output_shape(self) -> torch.Size:\n",
    "        \"\"\"Get the output shape without the batch dimensions.\"\"\"\n",
    "        n_features = self.linear.weight.shape[0]\n",
    "        d_embedding = self.linear.weight.shape[2]\n",
    "        return torch.Size((n_features, d_embedding))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Do the forward pass.\"\"\"\n",
    "        if x.ndim != 2:\n",
    "            raise ValueError(\n",
    "                'For now, only inputs with exactly one batch dimension are supported.'\n",
    "            )\n",
    "\n",
    "        x_linear = None if self.linear0 is None else self.linear0(x)\n",
    "\n",
    "        x_ple = self.impl(x)\n",
    "        x_ple = self.linear(x_ple)\n",
    "        if self.activation is not None:\n",
    "            x_ple = self.activation(x_ple)\n",
    "        return x_ple if x_linear is None else x_linear + x_ple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b95744d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.2061374 -1.6543508 12.153855  -1.2604606  0.5480492]]\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "n_features = 5\n",
    "batch = 1\n",
    "\n",
    "x = 5 * np.random.randn(batch, n_features).astype(\"float32\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00fdd72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n",
      "tensor([[-2., -1.,  0.,  1.,  2.],\n",
      "        [-2., -1.,  0.,  1.,  2.],\n",
      "        [-2., -1.,  0.,  1.,  2.],\n",
      "        [-2., -1.,  0.,  1.,  2.],\n",
      "        [-2., -1.,  0.,  1.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "range = [-2.0, 2.0]\n",
    "n_features = x.shape[1]\n",
    "n_bins = 4\n",
    "\n",
    "bins = torch.linspace(range[0], range[1], n_bins + 1)\n",
    "stacked_bins = torch.stack([bins] * n_features)\n",
    "print(bins)\n",
    "print(stacked_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee432c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.001905202865600586 seconds\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  1.2061],\n",
      "         [ 0.3456,  0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  1.0000,  1.0000, 11.1539],\n",
      "         [ 0.7395,  0.0000,  0.0000,  0.0000],\n",
      "         [ 1.0000,  1.0000,  0.5480,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ple = PiecewiseLinearEncoding(stacked_bins)\n",
    "x_tensor = torch.from_numpy(x)\n",
    "\n",
    "start = time.time()\n",
    "output = ple(x_tensor)\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "\n",
    "output = output.view(batch, n_features, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1376e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Tensor(\n",
    "# [[[ 1.          1.          1.          1.2061377 ]\n",
    "#   [ 0.34564924  0.          0.          0.        ]\n",
    "#   [ 1.          1.          1.         11.153855  ]\n",
    "#   [ 0.7395394   0.          0.          0.        ]\n",
    "#   [ 1.          1.          0.5480492   0.        ]]], shape=(1, 5, 4), dtype=float32)\n",
    "# took 0.022 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c00095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dipper_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
